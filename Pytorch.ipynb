{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "abvU8SCx5sXY"
      },
      "outputs": [],
      "source": [
        "import torch #pytorch library that helps in building the deep leanring algorithms\n",
        "from torch import nn ##nn means neural network\n",
        "from torch.utils.data import DataLoader #performs the process of batching\n",
        "from torchvision import datasets #Inbuild dataset that pytorch library has - FashionMnist Dataset\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(root=\"data\",train=True,download=True,transform=ToTensor())\n",
        "test_data = datasets.FashionMNIST(root=\"data\",train=False,download=True,transform=ToTensor())"
      ],
      "metadata": {
        "id": "7WmCh_zG52cU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzxX_43N6drk",
        "outputId": "5c255de2-a806-40e2-d422-197bb68e470c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrW3MCPW6gY2",
        "outputId": "7b7e2d66-2bee-4579-8fa3-83d72e8a6257"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Batching of this data**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H9TIrVA66puM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data,batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Zh1heI0x6nBP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for X,y in test_dataloader: #Image - Color image shape (batch_size,number of channel,length,width)\n",
        "  print(X.shape)            #Image - Black and white image - number of channels is 1\n",
        "  print(y.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XpmHcHJ7aEt",
        "outputId": "504fe58e-ff1b-4283-8110-79bc551e2478"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #torch.cuda.is_available() checks for your system has gpu or cpu\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CXzvihYd7gRo",
        "outputId": "c4e6b58a-76f4-4897-8c17-2f383c1088b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module): #Child class and nn.Module is a parent class -- (defined in the pytorch library)\n",
        "\n",
        "  def __init__(self): #declare the architecture\n",
        "    super().__init__() #basically initailizes all the variables of the parent class\n",
        "    self.flatten = nn.Flatten() #28x28 image into a 764x1 vector\n",
        "    self.linear1 = nn.Linear(28*28,512)\n",
        "    self.linear2 = nn.Linear(512,512)\n",
        "    self.linear3 = nn.Linear(512,10)\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):#is always used to pass the inputs to the neural network\n",
        "    x = self.flatten(x)\n",
        "    x = self.linear1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.linear3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Xtle_yPE7nq6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model = model.to(device) #copies your entire architecture to the GPU"
      ],
      "metadata": {
        "id": "j6r2L97__UbO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss() #cross entropy loss\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3) #stochastic Gradient descent"
      ],
      "metadata": {
        "id": "BFNuTM0C_eOG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#steps in the GD : Batch of the input / Pass it to the model / Compute loss function / Update the weights\n",
        "\n",
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "  model.train() #putting the model in the training mode\n",
        "  for batch,(X,y) in enumerate(dataloader):\n",
        "    #sending the data to the GPU\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    #Compute predictions\n",
        "    pred = model(X)\n",
        "\n",
        "    #Compute loss\n",
        "    loss = loss_fn(pred,y)\n",
        "\n",
        "    #Backpropogation\n",
        "    loss.backward() #Wnew = Wold - lr*dl/dw\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print(f'Loss of the Model {loss.item()}')\n"
      ],
      "metadata": {
        "id": "cRxwYptFCpmH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader,model,loss_fn):\n",
        "  model.eval() #putting the model in the training mode\n",
        "  num_batched = len(dataloader)\n",
        "  test_loss, correct = 0,0\n",
        "  with torch.no_grad(): #We will not compute gradients for the test data\n",
        "    for X,y in dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      #Compute predictions\n",
        "      pred = model(X)\n",
        "\n",
        "      #Compute loss\n",
        "      test_loss += loss_fn(pred,y).item()\n",
        "\n",
        "      #Find how many correct predictions\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss = test_loss/num_batched\n",
        "  correct = correct/(len(dataloader.dataset))\n",
        "\n",
        "  print(f'Test Accuracy {100*correct}, Avg_loss : {test_loss}')\n"
      ],
      "metadata": {
        "id": "fFuIiH3hCtSJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "for t in range(5):\n",
        "  print(f'Epoch {t+1}')\n",
        "  train(train_dataloader,model,loss_fn,optimizer)\n",
        "  test(test_dataloader,model,loss_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bIqY4FmC5a5",
        "outputId": "3dbb9e87-0a37-4a33-e841-1aa4fc58e3dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Loss of the Model 2.302501916885376\n",
            "Loss of the Model 2.2908520698547363\n",
            "Loss of the Model 2.2748072147369385\n",
            "Loss of the Model 2.2680413722991943\n",
            "Loss of the Model 2.2573087215423584\n",
            "Loss of the Model 2.235004186630249\n",
            "Loss of the Model 2.239778995513916\n",
            "Loss of the Model 2.2135329246520996\n",
            "Loss of the Model 2.213132381439209\n",
            "Loss of the Model 2.1839537620544434\n",
            "Test Accuracy 50.42, Avg_loss : 2.1767884682697853\n",
            "Epoch 2\n",
            "Loss of the Model 2.188882350921631\n",
            "Loss of the Model 2.183500289916992\n",
            "Loss of the Model 2.1307737827301025\n",
            "Loss of the Model 2.142164707183838\n",
            "Loss of the Model 2.1095199584960938\n",
            "Loss of the Model 2.051478862762451\n",
            "Loss of the Model 2.0818376541137695\n",
            "Loss of the Model 2.014612913131714\n",
            "Loss of the Model 2.021108865737915\n",
            "Loss of the Model 1.955333948135376\n",
            "Test Accuracy 58.830000000000005, Avg_loss : 1.9535347542185693\n",
            "Epoch 3\n",
            "Loss of the Model 1.979581594467163\n",
            "Loss of the Model 1.9650651216506958\n",
            "Loss of the Model 1.8521820306777954\n",
            "Loss of the Model 1.890448808670044\n",
            "Loss of the Model 1.7971073389053345\n",
            "Loss of the Model 1.733546257019043\n",
            "Loss of the Model 1.7633285522460938\n",
            "Loss of the Model 1.6594704389572144\n",
            "Loss of the Model 1.684865117073059\n",
            "Loss of the Model 1.5767489671707153\n",
            "Test Accuracy 61.36000000000001, Avg_loss : 1.5928744814198488\n",
            "Epoch 4\n",
            "Loss of the Model 1.6490631103515625\n",
            "Loss of the Model 1.6249732971191406\n",
            "Loss of the Model 1.472382664680481\n",
            "Loss of the Model 1.5443636178970337\n",
            "Loss of the Model 1.419845700263977\n",
            "Loss of the Model 1.4025864601135254\n",
            "Loss of the Model 1.4233613014221191\n",
            "Loss of the Model 1.3352009057998657\n",
            "Loss of the Model 1.3769420385360718\n",
            "Loss of the Model 1.263714075088501\n",
            "Test Accuracy 63.05, Avg_loss : 1.295602616231153\n",
            "Epoch 5\n",
            "Loss of the Model 1.3697699308395386\n",
            "Loss of the Model 1.3570424318313599\n",
            "Loss of the Model 1.1908525228500366\n",
            "Loss of the Model 1.2970590591430664\n",
            "Loss of the Model 1.1645647287368774\n",
            "Loss of the Model 1.1834464073181152\n",
            "Loss of the Model 1.207016944885254\n",
            "Loss of the Model 1.1322150230407715\n",
            "Loss of the Model 1.1798540353775024\n",
            "Loss of the Model 1.082221269607544\n",
            "Test Accuracy 64.63, Avg_loss : 1.1107598596317754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"/content/iteration1.pth\")"
      ],
      "metadata": {
        "id": "HIJWgfbIC8aE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/iteration1.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByuCGBjaC-4Z",
        "outputId": "27fbf349-c8b5-4129-eec6-0f74a1fc38dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classes = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"]\n",
        "\n",
        "model.eval()\n",
        "X,y = test_data[0][0], test_data[0][1]\n",
        "\n",
        "with torch.no_grad():\n",
        "  X = X.to(device)\n",
        "  pred = model(X)\n",
        "  predicted,actual = classes[pred[0].argmax(0)],classes[y]\n",
        "  print(f'Predicted {predicted}')\n",
        "  print(f'Actual {actual}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cmxrVZUD1D9",
        "outputId": "2886de98-f30c-47e6-8217-3fd394f5794f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Ankle Boot\n",
            "Actual Ankle Boot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7tqatRqzMP9",
        "outputId": "5044526d-c9b0-4c25-bc35-47d435d847bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}